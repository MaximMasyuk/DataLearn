{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "900410e0-01d7-4848-9d57-c3d39d60836d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+\n",
      "|STATE|avg(SCHEDULED_TIME)|\n",
      "+-----+-------------------+\n",
      "|   GU| 432.02095808383234|\n",
      "|   AS|  320.8878504672897|\n",
      "|   PR| 213.46459548377447|\n",
      "|   NJ| 189.29998890676134|\n",
      "|   VI|  186.5099300170229|\n",
      "+-----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.types import StructType, StringType\n",
    "\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "def extract_data(spark: SparkSession) -> DataFrame:\n",
    "    path = \"data/flights.csv\"\n",
    "    path1 = 'data/airports.csv'\n",
    "    path3 = 'data/airlines.csv'\n",
    "    dataF = [spark.read.option(\"header\", \"true\").csv(path), \n",
    "             spark.read.option(\"header\", \"true\").csv(path1), \n",
    "             spark.read.option(\"header\", \"true\").csv(path3) ]\n",
    "    return dataF\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def divert_flights(df1: DataFrame , df2: DataFrame) -> DataFrame:\n",
    "\n",
    "    df = df1.join(df2,df1.DESTINATION_AIRPORT == df2.IATA_CODE,how='left')\n",
    "    output = (\n",
    "        df.filter(F.col('DIVERTED') == 1)\n",
    "        .filter(F.col('COUNTRY') == 'USA')\n",
    "        .groupBy(\"AIRPORT\")\n",
    "        .agg(F.count(\"DIVERTED\"))\n",
    "        .orderBy(F.count(\"DIVERTED\"), ascending=False)\n",
    "        .show(5)\n",
    "        \n",
    "    )\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def  canceled_flights(df1: DataFrame , df2: DataFrame) -> DataFrame:\n",
    "    ddf1 = df1.withColumnRenamed(\"AIRLINE\", \"IATA_CODE\")\n",
    "    \n",
    "    df = ddf1.join(df2,ddf1.IATA_CODE == df2.IATA_CODE,how='left')\n",
    "    \n",
    "    output = (\n",
    "        df.filter(F.col('CANCELLED') == 1)\n",
    "        .groupBy('AIRLINE')\n",
    "        .agg(F.count(\"CANCELLED\"))\n",
    "        .orderBy(F.count(\"CANCELLED\"), ascending=False).show(3))\n",
    "        \n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def avg_time(df1: DataFrame , df2: DataFrame) -> DataFrame:\n",
    "\n",
    "    df = df1.join(df2,df1.ORIGIN_AIRPORT == df2.IATA_CODE,how='left')\n",
    "\n",
    "    output = (\n",
    "        df.filter(F.col('COUNTRY') == 'USA')\n",
    "        .groupBy('STATE').agg(F.avg('SCHEDULED_TIME')).orderBy(F.avg('SCHEDULED_TIME'), ascending=False).show(5)\n",
    "    )\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    spark = SparkSession.builder.appName(\"sparkDL\").getOrCreate()\n",
    "\n",
    "    dfs = extract_data(spark)\n",
    "    dfflies = dfs[0]\n",
    "    dfairports = dfs[1]\n",
    "    dfairline = dfs[2]\n",
    "    #canceled_flights(dfflies, dfairline)\n",
    "    #divert_flights(dfflies,dfairports)\n",
    "    avg_time(dfflies,dfairports)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68adb225-dad0-4b1e-83b7-5b991529e246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
